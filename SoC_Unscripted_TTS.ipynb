{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SoC - Unscripted - TTS.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDnaS1ira55b"
      },
      "source": [
        "# To wrap text in the output\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "KR2gNywtW4Qm",
        "outputId": "c5eff08f-f1f1-4714-ca33-4cd97267267e"
      },
      "source": [
        "# Install SpeechRecognition and jiwer libraries\n",
        "!pip install SpeechRecognition jiwer"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.7/dist-packages (3.8.1)\n",
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.7/dist-packages (2.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from jiwer) (1.19.5)\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.7/dist-packages (from jiwer) (0.12.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein->jiwer) (57.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "QZHGILD4W6Z-",
        "outputId": "588c7a59-0505-43e4-d8f6-eaa81f000f06"
      },
      "source": [
        "# Imports\n",
        "import speech_recognition as sr\n",
        "from jiwer import wer\n",
        "# sr.__version__"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "0H0Jl2KTaA5f",
        "outputId": "068526a1-eac2-47e5-f611-1beb02d90441"
      },
      "source": [
        "# Define Ground Truth corresponding to the Welcome.wav file\n",
        "ground_truth = \"Thank you for choosing the Olympus dictation management system. The Olympus dictation management system gives you the power to manage your dictation transcriptions and documents seamlessly and to improve the productivity of your daily work for example you can automatically sends the dictation files or transcribed documents to your assistant of the Otha via email or FTP. If you are using the speech recognition software the speech recognition engine works in the background to support your document creation. We hope you enjoy the simple flexible reliable and secure solutions from Olympus.\""
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "aF6RWvDUXwjH",
        "outputId": "3576615e-636f-49e9-b464-b1de3dddd356"
      },
      "source": [
        "# STT using Google Web Speech API - Requires internet\n",
        "r = sr.Recognizer()\n",
        "\n",
        "hellow = sr.AudioFile('Welcome.wav')\n",
        "with hellow as source:\n",
        "    audio = r.record(source)\n",
        "try:\n",
        "    s = r.recognize_google(audio)\n",
        "    print(\"Text: \"+s)\n",
        "    error = wer(ground_truth, s)\n",
        "    print(\"WER: \"+str(error))\n",
        "except Exception as e:\n",
        "    print(\"Exception: \"+str(e))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Text: thank you for choosing the Olympus dictation management system the Olympus dictation management system gives you the power to manage your dictations transcriptions and document seamlessly and to improve the productivity of your daily work for example you can automatically send the dictation files or transcribed documents do your assistant ociosa via email or fdp if you're using the speech recognition software the speech recognition engine works in the background to support your document creation we hope you enjoy the simple flexible reliable and Secure Solutions from Olympus\n",
            "WER: 0.2087912087912088\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2ysBpGO0Y4WL",
        "outputId": "991548bc-8fe6-42a8-e4e4-02ac027414a8"
      },
      "source": [
        "# STT using Bing Speech API - Requires internet\n",
        "r = sr.Recognizer()\n",
        "\n",
        "hellow = sr.AudioFile('Welcome.wav')\n",
        "with hellow as source:\n",
        "    audio = r.record(source)\n",
        "try:\n",
        "    s = r.recognize_bing(audio)\n",
        "    print(\"Text: \"+s)\n",
        "    error = wer(ground_truth, s)\n",
        "    print(\"WER: \"+str(error))\n",
        "except Exception as e:\n",
        "    print(\"Exception: \"+str(e))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Exception: recognize_bing() missing 1 required positional argument: 'key'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCAZn0WMbhXl"
      },
      "source": [
        "# STT using Houndify - Requires internet\n",
        "r = sr.Recognizer()\n",
        "\n",
        "hellow = sr.AudioFile('Welcome.wav')\n",
        "with hellow as source:\n",
        "    audio = r.record(source)\n",
        "try:\n",
        "    s = r.recognize_houndify(audio)\n",
        "    print(\"Text: \"+s)\n",
        "    error = wer(ground_truth, s)\n",
        "    print(\"WER: \"+str(error))\n",
        "except Exception as e:\n",
        "    print(\"Exception: \"+str(e))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqkugEY0bmlK"
      },
      "source": [
        "# STT using IBM STT - Requires internet\n",
        "r = sr.Recognizer()\n",
        "\n",
        "hellow = sr.AudioFile('Welcome.wav')\n",
        "with hellow as source:\n",
        "    audio = r.record(source)\n",
        "try:\n",
        "    s = r.recognize_ibm(audio)\n",
        "    print(\"Text: \"+s)\n",
        "    error = wer(ground_truth, s)\n",
        "    print(\"WER: \"+str(error))\n",
        "except Exception as e:\n",
        "    print(\"Exception: \"+str(e))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_chclLVbr1j"
      },
      "source": [
        "# STT using Wit.ai - Requires internet\n",
        "r = sr.Recognizer()\n",
        "\n",
        "hellow = sr.AudioFile('Welcome.wav')\n",
        "with hellow as source:\n",
        "    audio = r.record(source)\n",
        "try:\n",
        "    s = r.recognize_wit(audio)\n",
        "    print(\"Text: \"+s)\n",
        "    error = wer(ground_truth, s)\n",
        "    print(\"WER: \"+str(error))\n",
        "except Exception as e:\n",
        "    print(\"Exception: \"+str(e))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqD7kDQJb0k5"
      },
      "source": [
        "# Install Pocket Sphinx\n",
        "!pip install pocketsphinx\n",
        "\n",
        "# STT using CMU Sphinx\n",
        "r = sr.Recognizer()\n",
        "\n",
        "hellow = sr.AudioFile('Welcome.wav')\n",
        "with hellow as source:\n",
        "    audio = r.record(source)\n",
        "try:\n",
        "    s = r.recognize_sphinx(audio)\n",
        "    print(\"Text: \"+s)\n",
        "    error = wer(ground_truth, s)\n",
        "    print(\"WER: \"+str(error))\n",
        "except Exception as e:\n",
        "    print(\"Exception: \"+str(e))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}